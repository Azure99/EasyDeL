from .nn_funcs import Array, matmul, linear, embedding, rms_layernorm


struct Linear[DT: DType, nelts: Int, cores: Int, parallelized: Bool]:
    var weight: Array[DT]
    var bias: Array[DT]
    var has_bias: Bool

    fn __init__(inout self: Self, weight: Array[DT], bias: Array[DT]):
        self.weight = weight
        self.bias = bias
        self.has_bias = True

    fn __init__(inout self: Self, weight: Array[DT]):
        self.weight = weight
        self.bias = Array[DT](0)
        self.has_bias = False

    fn __call__(self: Self, x: Array[DT]) -> Array[DT]:
        var out = matmul[DT, nelts, cores, parallelized](x, self.weight)
        if self.has_bias:
            out = out + self.bias
        return out


struct Embedding[DT: DType, nelts: Int, cores: Int]:
    var weight: Array[DT]

    fn __init__(inout self: Self, weight: Array[DT]):
        self.weight = weight

    fn __call__(self: Self, input_ids: VariadicList[Int]) -> Array[DT]:
        let embed = embedding[DT, nelts, cores](input_ids, self.weight)
        return embed


struct RMSLayernorm[DT: DType, nelts: Int, cores: Int]:
    var weight: Array[DT]
    var epsilon: SIMD[DT, 1]

    fn __init__(inout self: Self, weight: Array[DT], epsilon: SIMD[DT, 1]):
        self.weight = weight
        self.epsilon = epsilon

    fn __call__(self: Self, x: Array[DT]) -> Array[DT]:
        let output: Array[DT] = rms_layernorm[DT, nelts, cores](
            x, self.weight, self.epsilon
        )

        return output
