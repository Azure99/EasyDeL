from ..array import Array, ArrayShape
from algorithm.functional import vectorize, parallelize
from math import math
from memory import memset_zero


@always_inline
fn rms_norm[
    T: DType, nelts: Int
](
    inout C: Array[T],
    x: Array[T],
    w: Array[T],
    epsilon: SIMD[T, 1],
    num_elements: Int = 0,
) -> None:
    var sp: SIMD[T, nelts] = SIMD[T, nelts](0.0)
    let nml: Int = num_elements if num_elements > 0 else x.num_elements()

    @parameter
    fn _do_sum_pow[_nelts: Int](size: Int):
        if _nelts < nelts:
            sp[0] += (x.load[_nelts](size) ** 2).reduce_add()
        else:
            sp += x.load[nelts](size) ** 2

    vectorize[nelts, _do_sum_pow](nml)
    var normed: SIMD[T, 1] = sp.reduce_add()
    normed = normed / nml + epsilon
    normed = 1.0 / math.sqrt(normed)

    @parameter
    fn _do_element_wise[_nelts: Int](j: Int):
        let val = w.data.simd_load[_nelts](j) * normed * x.data.simd_load[_nelts](j)
        C.data.offset(j).simd_store[_nelts](0, val)

    vectorize[nelts, _do_element_wise](nml)


fn rope[
    T: DType
](
    inout q_array: Array[T],
    inout k_array: Array[T],
    fcr_row: DTypePointer[T],
    fci_row: DTypePointer[T],
    num_attention_heads: Int,
    num_key_value_heads: Int,
    head_dims: Int,
    num_cores: Int = 1,
) -> None:
    @parameter
    fn _row(i: Int):
        for j in range(0, head_dims, 2):
            let fcr = fcr_row.offset(j // 2).load(0)
            let fci = fci_row.offset(j // 2).load(0)
            let q0 = q_array.data.offset(i * head_dims + j).load(0)
            let q1 = q_array.data.offset(i * head_dims + j + 1).load(0)
            q_array.data.offset(i * head_dims + j).store(0, q0 * fcr - q1 * fci)
            q_array.data.offset(i * head_dims + j + 1).store(0, q0 * fci + q1 * fcr)
            if i < num_key_value_heads:
                let k0 = k_array.data.offset(i * head_dims + j).load(0)
                let k1 = k_array.data.offset(i * head_dims + j + 1).load(0)
                k_array.data.offset(i * head_dims + j).store(0, k0 * fcr - k1 * fci)
                k_array.data.offset(i * head_dims + j + 1).store(0, k0 * fci + k1 * fcr)

    parallelize[_row](num_attention_heads, num_cores)


@always_inline
fn attention_weight[
    T: DType, nelts: Int
](
    C: Array[T],
    attn: Array[T],
    q: Array[T],
    k_cache: Array[T],
    v_cache: Array[T],
    pad: Int,
    head_dims: Int,
    number_rep_kv: Int,
    max_position_embeddings: Int,
    position: Int,
    num_key_value_heads: Int,
    num_attention_heads: Int,
    num_cores: Int = 1,
):
    @parameter
    fn _calculate_each_head(head_index: Int):
        let kv_dims: Int = num_key_value_heads * head_dims
        let q_ = q.data.offset(head_index * head_dims)
        var C_AT = attn.data.offset(head_index * max_position_embeddings)
        for position_index in range(position + 1):
            let k_offset = pad + position_index * kv_dims + (
                head_index // number_rep_kv
            ) * head_dims
            let k = k_cache.data.offset(k_offset)

            var score: SIMD[T, 1] = SIMD[T, 1](0.0)
            for dim_index in range(head_dims):
                score += k.offset(dim_index).load(0) * q_.offset(dim_index).load(0)

            score /= math.sqrt[T, 1](head_dims)

            C_AT.offset(position_index).store(0, score)
        softmax[T, nelts](C_AT, position + 1)

        let H_S = C.data.offset(head_index * head_dims)
        memset_zero(H_S, head_dims)
        for position_index in range(position + 1):
            let v_offset: Int = pad + position_index * kv_dims + (
                head_index // number_rep_kv
            ) * head_dims
            let v = v_cache.data.offset(v_offset)
            let A = C_AT.offset(position_index).load(0)
            for ii in range(head_dims):
                let x_ = H_S.offset(ii).load(0) + A * v.offset(ii).load(0)
                H_S.offset(ii).store(0, x_)

    parallelize[_calculate_each_head](num_attention_heads, num_cores)
