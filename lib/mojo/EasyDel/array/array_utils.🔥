from python import PythonObject
from .array_module import ArrayShape, Array, dims_average_size
from algorithm.functional import (
    vectorize,
    parallelize,
    vectorize_unroll,
    Static2DTileUnitFunc as Tile2D,
)
from math import min


@always_inline
fn convert_numpy_to_easydel_array[
    T: DType
](np_array: PythonObject, array_spec: ArrayShape) raises -> Array[T]:
    let size: Int = array_spec.num_elements()
    var dynamic_vector = DynamicVector[FloatLiteral](size)
    dynamic_vector.reserve(size)
    try:
        for i in range(size):
            if size == 1:
                dynamic_vector.push_back(np_array.__index__())
            else:
                dynamic_vector.push_back(np_array.reshape(-1)[i].__index__())
    except:
        print("couldn't make it")
        return Array[T](array_spec)
    return Array[T](dynamic_vector, array_spec)


@always_inline
fn matmul_2d[
    T: DType, nelts: Int
](C: Array[T], A: Array[T], B: Array[T], num_cores: Int = 1) -> None:
    @parameter
    fn CI(y: Int, x: Int) -> Int:
        return y * C.dim(-1) + x

    @parameter
    fn AI(y: Int, x: Int) -> Int:
        return y * A.dim(-1) + x

    @parameter
    fn BI(y: Int, x: Int) -> Int:
        return y * B.dim(-1) + x

    @parameter
    fn loop_(i: Int) -> None:
        for j in range(A.dim(-1)):

            @parameter
            fn _mul[_nelts: Int](k: Int) -> None:
                let ci: Int = CI(i, k)
                let ai: Int = AI(i, j)
                let bi: Int = BI(j, k)

                C.store[_nelts](ci, C.load[_nelts](ci) + A[ai] * B.load[_nelts](bi))

            vectorize[nelts, _mul](C.dim(-1))

    parallelize[loop_](C.dim(-2), num_cores)


@always_inline
fn matmul[
    T: DType, nelts: Int
](C: Array[T], A: Array[T], B: Array[T], num_cores: Int = 1) raises -> None:
    if A.rank() == 2 and B.rank() == 1 and (C.rank() == 1 or C.rank() == 2):
        matmul_single_row[T, nelts](C, A, B, num_cores)
        return
    if A.rank() != B.rank():
        raise Error("Can not performe operation Dimensions won't match")
    let C_C: Int = C.dim(-1)
    let A_C: Int = A.dim(-1)
    let C_R: Int = C.dim(-2)
    let C_P: Int = C.dim(-2) * C.dim(-1)
    let B_P: Int = B.dim(-2) * B.dim(-1)
    let A_P: Int = A.dim(-2) * A.dim(-1)

    @parameter
    fn CI(y: Int, x: Int) -> Int:
        return y * C.dim(-1) + x

    @parameter
    fn AI(y: Int, x: Int) -> Int:
        return y * A.dim(-1) + x

    @parameter
    fn BI(y: Int, x: Int) -> Int:
        return y * B.dim(-1) + x

    for s in range((C.num_elements() // (C_C * C_R))):
        let pad_ci = s * C_P
        let pad_ai = s * A_P
        let pad_bi = s * B_P

        @parameter
        fn loop_(i: Int) -> None:
            for j in range(A_C):

                @parameter
                fn _mul[_nelts: Int](k: Int) -> None:
                    let ci: Int = CI(i, k) + pad_ci
                    let ai: Int = AI(i, j) + pad_ai
                    let bi: Int = BI(j, k) + pad_bi
                    C.store[_nelts](ci, C.load[_nelts](ci) + A[ai] * B.load[_nelts](bi))

                vectorize[nelts, _mul](C_C)

        parallelize[loop_](C_R, num_cores)


@always_inline
fn matmul_shape[T: DType](A: Array[T], B: Array[T]) -> ArrayShape:
    if A.rank() == 2 and B.rank() == 1:
        return ArrayShape(A.dim(0))
    else:
        var res_dims = InlinedFixedVector[dims_average_size, Int](A.rank())
        for i in range(A.rank() - 1):
            res_dims.append(A.dim(i))
        res_dims.append(B.dim(-1))

        return ArrayShape(res_dims)


@always_inline
fn matmul_single_row[
    T: DType, nelts: Int
](C: Array[T], A: Array[T], B: Array[T], num_cores: Int = 1):
    if not (A.rank() == 2 and B.rank() == 1 and (C.rank() == 1 or C.rank() == 2)):
        print("Report Matmul Bug in matmul_single_row")
    let A_C: Int = A.dim(-1)

    @parameter
    fn _loop(i: Int):
        var tensor = SIMD[T, nelts](0.0)

        @parameter
        fn dot[_nelts: Int](j: Int):
            if _nelts < nelts:
                tensor[0] += (A.load[_nelts](i, j) * B.load[_nelts](j)).reduce_add()
            else:
                tensor += A.load[nelts](i, j) * B.load[nelts](j)

        vectorize[nelts, dot](A_C)
        C[i] = tensor.reduce_add()

    parallelize[_loop](A.dim(-2), num_cores)


@always_inline
fn matmul_single_row[
    T: DType, nelts: Int
](
    C: DTypePointer[T],
    A: DTypePointer[T],
    B: DTypePointer[T],
    AC: Int,
    AR: Int,
    num_cores: Int = 1,
):
    @parameter
    fn _loop(i: Int):
        var tensor = SIMD[T, nelts](0)

        @parameter
        fn dot[_nelts: Int](j: Int):
            if _nelts < nelts:
                tensor[0] += (
                    A.simd_load[_nelts](i * AC + j) * B.simd_load[_nelts](j)
                ).reduce_add()
            else:
                tensor += A.simd_load[nelts](i * AC + j) * B.simd_load[nelts](j)

        vectorize[nelts, dot](AC)
        C.store(i, tensor.reduce_add())

    parallelize[_loop](AR, num_cores)
