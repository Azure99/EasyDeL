Index: EasyDel/weight_convertor/mpt.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from jax import numpy as jnp\nimport jax\n\n\ndef convert_pt_to_flax_7b(state_dict_pt,n_layers:int, device=jax.devices('cpu')[0], use_lm_head=False):\n    # CONVERTER MPT-7B\n    with jax.default_device(device):\n        state_dict_flax = {}\n        state_dict_flax[('transformer'), ('wte'), ('embedding')] = state_dict_pt[\n            'transformer.wte.weight'].cpu().detach().numpy()\n        for i in range(n_layers):\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('norm_1'), ('scale')] = state_dict_pt[\n                f'transformer.blocks.{i}.norm_1.weight'].cpu().detach().numpy()\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('norm_2'), ('scale')] = state_dict_pt[\n                f'transformer.blocks.{i}.norm_2.weight'].cpu().detach().numpy()\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('ffn'), ('down'), ('kernel')] = jnp.transpose(\n                state_dict_pt[f'transformer.blocks.{i}.ffn.down_proj.weight'].cpu().detach().numpy(), (1, 0))\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('ffn'), ('up'), ('kernel')] = jnp.transpose(\n                state_dict_pt[f'transformer.blocks.{i}.ffn.up_proj.weight'].cpu().detach().numpy(), (1, 0))\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('w_qkv'), ('kernel')] = jnp.transpose(\n                state_dict_pt[f'transformer.blocks.{i}.attn.Wqkv.weight'].cpu().detach().numpy(), (1, 0))\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('wo'), ('kernel')] = jnp.transpose(\n                state_dict_pt[f'transformer.blocks.{i}.attn.out_proj.weight'].cpu().detach().numpy(), (1, 0))\n        state_dict_flax[('transformer'), ('norm_f'), ('scale')] = state_dict_pt[\n            f'transformer.norm_f.weight'].cpu().detach().numpy()\n        if use_lm_head:\n            state_dict_flax[('lm_head'), ('kernel')] = jnp.transpose(\n                state_dict_pt[f'lm_head.weight'].cpu().detach().numpy(), (1, 0))\n    return state_dict_flax\n\n\ndef convert_pt_to_flax_1b(state_dict_pt, n_layers: int, device=jax.devices('cpu')[0], use_lm_head=False, ):\n    # CONVERTER MPT-1B\n    with jax.default_device(device):\n        state_dict_flax = {}\n        state_dict_flax[('transformer'), ('wte'), ('embedding')] = state_dict_pt[\n            'transformer.wte.weight'].cpu().detach().numpy()\n        for i in range(n_layers):\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('norm_1'), ('scale')] = state_dict_pt[\n                f'transformer.blocks.{i}.ln_1.weight'].cpu().detach().numpy()\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('norm_2'), ('scale')] = state_dict_pt[\n                f'transformer.blocks.{i}.ln_2.weight'].cpu().detach().numpy()\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('ffn'), ('down'), ('kernel')] = jnp.transpose(\n                state_dict_pt[f'transformer.blocks.{i}.mlp.mlp_down.weight'].cpu().detach().numpy(), (1, 0))\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('ffn'), ('up'), ('kernel')] = jnp.transpose(\n                state_dict_pt[f'transformer.blocks.{i}.mlp.mlp_up.weight'].cpu().detach().numpy(), (1, 0))\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('w_qkv'), ('kernel')] = jnp.transpose(\n                state_dict_pt[f'transformer.blocks.{i}.attn.Wqkv.weight'].cpu().detach().numpy(), (1, 0))\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('wo'), ('kernel')] = jnp.transpose(\n                state_dict_pt[f'transformer.blocks.{i}.attn.out_proj.weight'].cpu().detach().numpy(), (1, 0))\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('q_ln'), ('scale')] = state_dict_pt[\n                f'transformer.blocks.{i}.attn.q_ln.weight'].cpu().detach().numpy()\n            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('k_ln'), ('scale')] = state_dict_pt[\n                f'transformer.blocks.{i}.attn.k_ln.weight'].cpu().detach().numpy()\n        state_dict_flax[('transformer'), ('norm_f'), ('scale')] = state_dict_pt[\n            f'transformer.ln_f.weight'].cpu().detach().numpy()\n        if use_lm_head:\n            state_dict_flax[('lm_head'), ('kernel')] = jnp.transpose(\n                state_dict_pt[f'lm_head.weight'].cpu().detach().numpy(),\n                (1, 0))\n    return state_dict_flax\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/EasyDel/weight_convertor/mpt.py b/EasyDel/weight_convertor/mpt.py
--- a/EasyDel/weight_convertor/mpt.py	(revision 102b81d21d324641570a3507e30498f4d6e48f2b)
+++ b/EasyDel/weight_convertor/mpt.py	(date 1687105392601)
@@ -2,30 +2,30 @@
 import jax
 
 
-def convert_pt_to_flax_7b(state_dict_pt,n_layers:int, device=jax.devices('cpu')[0], use_lm_head=False):
+def convert_pt_to_flax_7b(state_dict_pt, n_layers: int, device=jax.devices('cpu')[0], use_lm_head=False):
     # CONVERTER MPT-7B
     with jax.default_device(device):
         state_dict_flax = {}
-        state_dict_flax[('transformer'), ('wte'), ('embedding')] = state_dict_pt[
+        state_dict_flax[('transformer', 'wte', 'embedding')] = state_dict_pt[
             'transformer.wte.weight'].cpu().detach().numpy()
         for i in range(n_layers):
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('norm_1'), ('scale')] = state_dict_pt[
+            state_dict_flax[('transformer', 'h', f'{i}', 'norm_1', 'norm_2')] = state_dict_pt[
                 f'transformer.blocks.{i}.norm_1.weight'].cpu().detach().numpy()
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('norm_2'), ('scale')] = state_dict_pt[
+            state_dict_flax[('transformer', 'h', f'{i}', 'norm_2', 'norm_2')] = state_dict_pt[
                 f'transformer.blocks.{i}.norm_2.weight'].cpu().detach().numpy()
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('ffn'), ('down'), ('kernel')] = jnp.transpose(
+            state_dict_flax[('transformer', 'h', f'{i}', 'ffn', 'down', 'kernel')] = jnp.transpose(
                 state_dict_pt[f'transformer.blocks.{i}.ffn.down_proj.weight'].cpu().detach().numpy(), (1, 0))
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('ffn'), ('up'), ('kernel')] = jnp.transpose(
+            state_dict_flax[('transformer', 'h', f'{i}', 'ffn', 'up', 'kernel')] = jnp.transpose(
                 state_dict_pt[f'transformer.blocks.{i}.ffn.up_proj.weight'].cpu().detach().numpy(), (1, 0))
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('w_qkv'), ('kernel')] = jnp.transpose(
+            state_dict_flax[('transformer', 'h', f'{i}', 'attn', 'w_qkv', 'kernel')] = jnp.transpose(
                 state_dict_pt[f'transformer.blocks.{i}.attn.Wqkv.weight'].cpu().detach().numpy(), (1, 0))
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('wo'), ('kernel')] = jnp.transpose(
+            state_dict_flax[('transformer', 'h', f'{i}', 'attn', 'wo', 'kernel')] = jnp.transpose(
                 state_dict_pt[f'transformer.blocks.{i}.attn.out_proj.weight'].cpu().detach().numpy(), (1, 0))
-        state_dict_flax[('transformer'), ('norm_f'), ('scale')] = state_dict_pt[
-            f'transformer.norm_f.weight'].cpu().detach().numpy()
-        if use_lm_head:
-            state_dict_flax[('lm_head'), ('kernel')] = jnp.transpose(
-                state_dict_pt[f'lm_head.weight'].cpu().detach().numpy(), (1, 0))
+            state_dict_flax[('transformer', 'norm_f', 'norm_2')] = state_dict_pt[
+                f'transformer.norm_f.weight'].cpu().detach().numpy()
+            if use_lm_head:
+                state_dict_flax[('lm_head', 'kernel')] = jnp.transpose(
+                    state_dict_pt[f'lm_head.weight'].cpu().detach().numpy(), (1, 0))
     return state_dict_flax
 
 
@@ -33,29 +33,29 @@
     # CONVERTER MPT-1B
     with jax.default_device(device):
         state_dict_flax = {}
-        state_dict_flax[('transformer'), ('wte'), ('embedding')] = state_dict_pt[
+        state_dict_flax[('transformer', 'wte', 'embedding')] = state_dict_pt[
             'transformer.wte.weight'].cpu().detach().numpy()
         for i in range(n_layers):
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('norm_1'), ('scale')] = state_dict_pt[
+            state_dict_flax[('transformer', 'h', f'{i}', 'norm_1', 'norm_2')] = state_dict_pt[
                 f'transformer.blocks.{i}.ln_1.weight'].cpu().detach().numpy()
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('norm_2'), ('scale')] = state_dict_pt[
-                f'transformer.blocks.{i}.ln_2.weight'].cpu().detach().numpy()
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('ffn'), ('down'), ('kernel')] = jnp.transpose(
-                state_dict_pt[f'transformer.blocks.{i}.mlp.mlp_down.weight'].cpu().detach().numpy(), (1, 0))
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('ffn'), ('up'), ('kernel')] = jnp.transpose(
-                state_dict_pt[f'transformer.blocks.{i}.mlp.mlp_up.weight'].cpu().detach().numpy(), (1, 0))
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('w_qkv'), ('kernel')] = jnp.transpose(
-                state_dict_pt[f'transformer.blocks.{i}.attn.Wqkv.weight'].cpu().detach().numpy(), (1, 0))
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('wo'), ('kernel')] = jnp.transpose(
-                state_dict_pt[f'transformer.blocks.{i}.attn.out_proj.weight'].cpu().detach().numpy(), (1, 0))
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('q_ln'), ('scale')] = state_dict_pt[
-                f'transformer.blocks.{i}.attn.q_ln.weight'].cpu().detach().numpy()
-            state_dict_flax[('transformer'), ('h'), (f'{i}'), ('attn'), ('k_ln'), ('scale')] = state_dict_pt[
-                f'transformer.blocks.{i}.attn.k_ln.weight'].cpu().detach().numpy()
-        state_dict_flax[('transformer'), ('norm_f'), ('scale')] = state_dict_pt[
+        state_dict_flax[('transformer', 'h', f'{i}', 'norm_2', 'norm_2')] = state_dict_pt[
+            f'transformer.blocks.{i}.ln_2.weight'].cpu().detach().numpy()
+        state_dict_flax[('transformer', 'h', f'{i}', 'ffn', 'down', 'kernel')] = jnp.transpose(
+            state_dict_pt[f'transformer.blocks.{i}.mlp.mlp_down.weight'].cpu().detach().numpy(), (1, 0))
+        state_dict_flax[('transformer', 'h', f'{i}', 'ffn', 'up', 'kernel')] = jnp.transpose(
+            state_dict_pt[f'transformer.blocks.{i}.mlp.mlp_up.weight'].cpu().detach().numpy(), (1, 0))
+        state_dict_flax[('transformer', 'h', f'{i}', 'attn', 'w_qkv', 'kernel')] = jnp.transpose(
+            state_dict_pt[f'transformer.blocks.{i}.attn.Wqkv.weight'].cpu().detach().numpy(), (1, 0))
+        state_dict_flax[('transformer', 'h', f'{i}', 'attn', 'wo', 'kernel')] = jnp.transpose(
+            state_dict_pt[f'transformer.blocks.{i}.attn.out_proj.weight'].cpu().detach().numpy(), (1, 0))
+        state_dict_flax[('transformer', 'h', f'{i}', 'attn', 'q_ln', 'norm_2')] = state_dict_pt[
+            f'transformer.blocks.{i}.attn.q_ln.weight'].cpu().detach().numpy()
+        state_dict_flax[('transformer', 'h', f'{i}', 'attn', 'k_ln', 'norm_2')] = state_dict_pt[
+            f'transformer.blocks.{i}.attn.k_ln.weight'].cpu().detach().numpy()
+        state_dict_flax[('transformer', 'norm_f', 'norm_2')] = state_dict_pt[
             f'transformer.ln_f.weight'].cpu().detach().numpy()
         if use_lm_head:
-            state_dict_flax[('lm_head'), ('kernel')] = jnp.transpose(
+            state_dict_flax[('lm_head', 'kernel')] = jnp.transpose(
                 state_dict_pt[f'lm_head.weight'].cpu().detach().numpy(),
                 (1, 0))
     return state_dict_flax
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"08ad205b-709f-455b-86db-91293f595cd3\" name=\"Changes\" comment=\"\">\n      <change afterPath=\"$PROJECT_DIR$/EasyDel/weight_convertor/llama.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Jupyter Notebook\" />\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n  </component>\n  <component name=\"MarkdownSettingsMigration\">\n    <option name=\"stateVersion\" value=\"1\" />\n  </component>\n  <component name=\"ProjectId\" id=\"2R3gggiusHG4H0D83vGO8YekTKm\" />\n  <component name=\"ProjectLevelVcsManager\">\n    <ConfirmationsSetting value=\"2\" id=\"Add\" />\n  </component>\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\">{\n  &quot;keyToString&quot;: {\n    &quot;RunOnceActivity.OpenProjectViewOnStart&quot;: &quot;true&quot;,\n    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,\n    &quot;WebServerToolWindowFactoryState&quot;: &quot;false&quot;,\n    &quot;git-widget-placeholder&quot;: &quot;main&quot;,\n    &quot;last_opened_file_path&quot;: &quot;/home/erfan/PycharmProjects/EasyDeL&quot;,\n    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,\n    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,\n    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,\n    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,\n    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,\n    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;\n  }\n}</component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/EasyDel/modules/gpt_j\" />\n    </key>\n  </component>\n  <component name=\"RunManager\">\n    <configuration default=\"true\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"EasyDL\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"true\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"env\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"EasyDeL\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/env.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"true\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <recent_temporary>\n      <list>\n        <item itemvalue=\"Python.env\" />\n      </list>\n    </recent_temporary>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"08ad205b-709f-455b-86db-91293f595cd3\" name=\"Changes\" comment=\"\" />\n      <created>1686484291658</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1686484291658</updated>\n      <workItem from=\"1686484292842\" duration=\"2671000\" />\n      <workItem from=\"1686569916737\" duration=\"787000\" />\n      <workItem from=\"1686662766563\" duration=\"2288000\" />\n      <workItem from=\"1686726437192\" duration=\"19074000\" />\n      <workItem from=\"1686759910414\" duration=\"82000\" />\n      <workItem from=\"1686759993630\" duration=\"2050000\" />\n      <workItem from=\"1686818314317\" duration=\"7718000\" />\n      <workItem from=\"1686839603867\" duration=\"3683000\" />\n      <workItem from=\"1686851148699\" duration=\"620000\" />\n      <workItem from=\"1686893808099\" duration=\"998000\" />\n    </task>\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision 102b81d21d324641570a3507e30498f4d6e48f2b)
+++ b/.idea/workspace.xml	(date 1687106019525)
@@ -5,8 +5,8 @@
   </component>
   <component name="ChangeListManager">
     <list default="true" id="08ad205b-709f-455b-86db-91293f595cd3" name="Changes" comment="">
-      <change afterPath="$PROJECT_DIR$/EasyDel/weight_convertor/llama.py" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/EasyDel/weight_convertor/mpt.py" beforeDir="false" afterPath="$PROJECT_DIR$/EasyDel/weight_convertor/mpt.py" afterDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
@@ -123,7 +123,8 @@
       <workItem from="1686818314317" duration="7718000" />
       <workItem from="1686839603867" duration="3683000" />
       <workItem from="1686851148699" duration="620000" />
-      <workItem from="1686893808099" duration="998000" />
+      <workItem from="1686893808099" duration="2131000" />
+      <workItem from="1687104864830" duration="1122000" />
     </task>
     <servers />
   </component>
