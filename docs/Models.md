# Model ðŸ¤–ðŸ’«

## Available Models Are

1. **_[Llama](https://erfanzar.github.io/EasyDeL/docs/Llama)_**:

    * Supports:
        * Fully Sharded Data Parallel `(FSDP)`
        * MultiProcessing `(MP)`
        * Data Parallel `(DP)`
        * Distributed Data Parallel  (DDP) `(DP)`
        * Gradient CheckPointing
        * Flash Attention
        * BlockWise Attention
        * Usage and Import from EasyDel Library
        * [Usage](https://erfanzar.github.io/EasyDeL/docs/Llama)


2. **_[Llama2](https://erfanzar.github.io/EasyDeL/docs/Llama2)_**:

    * Supports:
        * Fully Sharded Data Parallel `(FSDP)`
        * MultiProcessing `(MP)`
        * Data Parallel `(DP)`
        * Distributed Data Parallel  (DDP) `(DP)`
        * Gradient CheckPointing
        * Flash Attention
        * BlockWise Attention
        * [Usage](https://erfanzar.github.io/EasyDeL/docs/Llama2)


3. **_[Falcon](https://erfanzar.github.io/EasyDeL/docs/Falcon)_**:

    * Supports:
        * Fully Sharded Data Parallel `(FSDP)`
        * MultiProcessing `(MP)`
        * Data Parallel `(DP)`
        * Distributed Data Parallel  (DDP) `(DP)`
        * Gradient CheckPointing
        * Flash Attention
        * BlockWise Attention
        * [Usage](https://erfanzar.github.io/EasyDeL/docs/Falcon)


4. **_[MosaicMPT](https://erfanzar.github.io/EasyDeL/docs/MosaicMPT)_**:

    * Supports:
        * Fully Sharded Data Parallel `(FSDP)`
        * MultiProcessing `(MP)`
        * Data Parallel `(DP)`
        * Distributed Data Parallel  (DDP) `(DP)`
        * Gradient CheckPointing
        * Flash Attention
        * BlockWise Attention
        * [Usage](https://erfanzar.github.io/EasyDeL/docs/MosaicMPT)


5. **_GPTNeoX_**  :

    * Supports:
        * Fully Sharded Data Parallel `(FSDP)`
        * MultiProcessing `(MP)`
        * Data Parallel `(DP)`
        * Distributed Data Parallel  (DDP) `(DP)`
        * Gradient CheckPointing


6. **_LT_** :

    * Supports:
        * Fully Sharded Data Parallel `(FSDP)`
        * MultiProcessing `(MP)`
        * Data Parallel `(DP)`
        * Distributed Data Parallel  (DDP) `(DP)`
        * Gradient CheckPointing

7. **_Palm_**:

    * Supports:
        * Fully Sharded Data Parallel `(FSDP)`
        * MultiProcessing `(MP)`
        * Data Parallel `(DP)`
        * Distributed Data Parallel  (DDP) `(DP)`
        * Gradient CheckPointing


8. **_T5_**:

    * Supports:
        * Fully Sharded Data Parallel `(FSDP)`
        * MultiProcessing `(MP)`
        * Data Parallel `(DP)`
        * Distributed Data Parallel  (DDP) `(DP)`
        * Gradient CheckPointing

9. **_GPT-J_** :

    * Supports:
        * Fully Sharded Data Parallel `(FSDP)`
        * MultiProcessing `(MP)`
        * Data Parallel `(DP)`
        * Distributed Data Parallel  (DDP) `(DP)`
        * Gradient CheckPointing
        * Flash Attention
        * BlockWise Attention

10. **_OPT_**:

    * Supports:
        * Fully Sharded Data Parallel `(FSDP)`
        * MultiProcessing `(MP)`
        * Data Parallel `(DP)`
        * Distributed Data Parallel  (DDP) `(DP)`
        * Gradient CheckPointing
